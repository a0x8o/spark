/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";
package org.apache.spark.status.protobuf;

enum JobExecutionStatus {
  UNSPECIFIED = 0;
  RUNNING = 1;
  SUCCEEDED = 2;
  FAILED = 3;
  UNKNOWN = 4;
}

message JobData {
  // All IDs are int64 for extendability, even when they are currently int32 in Spark.
  int64 job_id = 1;
  string name = 2;
  optional string description = 3;
  optional int64 submission_time = 4;
  optional int64 completion_time = 5;
  repeated int64 stage_ids = 6;
  optional string job_group = 7;
  JobExecutionStatus status = 8;
  int32 num_tasks = 9;
  int32 num_active_tasks = 10;
  int32 num_completed_tasks = 11;
  int32 num_skipped_tasks = 12;
  int32 num_failed_tasks = 13;
  int32 num_killed_tasks = 14;
  int32 num_completed_indices = 15;
  int32 num_active_stages = 16;
  int32 num_completed_stages = 17;
  int32 num_skipped_stages = 18;
  int32 num_failed_stages = 19;
  map<string, int32> kill_tasks_summary = 20;
}

message JobDataWrapper {
  JobData info = 1;
  repeated int32 skipped_stages = 2;
  optional int64 sql_execution_id = 3;
}