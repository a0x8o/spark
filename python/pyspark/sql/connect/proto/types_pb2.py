#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: spark/connect/types.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database

# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
    b'\n\x19spark/connect/types.proto\x12\rspark.connect"\xec\x1d\n\x08\x44\x61taType\x12\x32\n\x04null\x18\x01 \x01(\x0b\x32\x1c.spark.connect.DataType.NULLH\x00R\x04null\x12\x38\n\x06\x62inary\x18\x02 \x01(\x0b\x32\x1e.spark.connect.DataType.BinaryH\x00R\x06\x62inary\x12;\n\x07\x62oolean\x18\x03 \x01(\x0b\x32\x1f.spark.connect.DataType.BooleanH\x00R\x07\x62oolean\x12\x32\n\x04\x62yte\x18\x04 \x01(\x0b\x32\x1c.spark.connect.DataType.ByteH\x00R\x04\x62yte\x12\x35\n\x05short\x18\x05 \x01(\x0b\x32\x1d.spark.connect.DataType.ShortH\x00R\x05short\x12;\n\x07integer\x18\x06 \x01(\x0b\x32\x1f.spark.connect.DataType.IntegerH\x00R\x07integer\x12\x32\n\x04long\x18\x07 \x01(\x0b\x32\x1c.spark.connect.DataType.LongH\x00R\x04long\x12\x35\n\x05\x66loat\x18\x08 \x01(\x0b\x32\x1d.spark.connect.DataType.FloatH\x00R\x05\x66loat\x12\x38\n\x06\x64ouble\x18\t \x01(\x0b\x32\x1e.spark.connect.DataType.DoubleH\x00R\x06\x64ouble\x12;\n\x07\x64\x65\x63imal\x18\n \x01(\x0b\x32\x1f.spark.connect.DataType.DecimalH\x00R\x07\x64\x65\x63imal\x12\x38\n\x06string\x18\x0b \x01(\x0b\x32\x1e.spark.connect.DataType.StringH\x00R\x06string\x12\x32\n\x04\x63har\x18\x0c \x01(\x0b\x32\x1c.spark.connect.DataType.CharH\x00R\x04\x63har\x12<\n\x08var_char\x18\r \x01(\x0b\x32\x1f.spark.connect.DataType.VarCharH\x00R\x07varChar\x12\x32\n\x04\x64\x61te\x18\x0e \x01(\x0b\x32\x1c.spark.connect.DataType.DateH\x00R\x04\x64\x61te\x12\x41\n\ttimestamp\x18\x0f \x01(\x0b\x32!.spark.connect.DataType.TimestampH\x00R\ttimestamp\x12K\n\rtimestamp_ntz\x18\x10 \x01(\x0b\x32$.spark.connect.DataType.TimestampNTZH\x00R\x0ctimestampNtz\x12W\n\x11\x63\x61lendar_interval\x18\x11 \x01(\x0b\x32(.spark.connect.DataType.CalendarIntervalH\x00R\x10\x63\x61lendarInterval\x12[\n\x13year_month_interval\x18\x12 \x01(\x0b\x32).spark.connect.DataType.YearMonthIntervalH\x00R\x11yearMonthInterval\x12U\n\x11\x64\x61y_time_interval\x18\x13 \x01(\x0b\x32\'.spark.connect.DataType.DayTimeIntervalH\x00R\x0f\x64\x61yTimeInterval\x12\x35\n\x05\x61rray\x18\x14 \x01(\x0b\x32\x1d.spark.connect.DataType.ArrayH\x00R\x05\x61rray\x12\x38\n\x06struct\x18\x15 \x01(\x0b\x32\x1e.spark.connect.DataType.StructH\x00R\x06struct\x12/\n\x03map\x18\x16 \x01(\x0b\x32\x1b.spark.connect.DataType.MapH\x00R\x03map\x1a\x43\n\x07\x42oolean\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a@\n\x04\x42yte\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a\x41\n\x05Short\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a\x43\n\x07Integer\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a@\n\x04Long\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a\x41\n\x05\x46loat\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a\x42\n\x06\x44ouble\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a\x42\n\x06String\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a\x42\n\x06\x42inary\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a@\n\x04NULL\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a\x45\n\tTimestamp\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a@\n\x04\x44\x61te\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1aH\n\x0cTimestampNTZ\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1aL\n\x10\x43\x61lendarInterval\x12\x38\n\x18type_variation_reference\x18\x01 \x01(\rR\x16typeVariationReference\x1a\xb3\x01\n\x11YearMonthInterval\x12$\n\x0bstart_field\x18\x01 \x01(\x05H\x00R\nstartField\x88\x01\x01\x12 \n\tend_field\x18\x02 \x01(\x05H\x01R\x08\x65ndField\x88\x01\x01\x12\x38\n\x18type_variation_reference\x18\x03 \x01(\rR\x16typeVariationReferenceB\x0e\n\x0c_start_fieldB\x0c\n\n_end_field\x1a\xb1\x01\n\x0f\x44\x61yTimeInterval\x12$\n\x0bstart_field\x18\x01 \x01(\x05H\x00R\nstartField\x88\x01\x01\x12 \n\tend_field\x18\x02 \x01(\x05H\x01R\x08\x65ndField\x88\x01\x01\x12\x38\n\x18type_variation_reference\x18\x03 \x01(\rR\x16typeVariationReferenceB\x0e\n\x0c_start_fieldB\x0c\n\n_end_field\x1aX\n\x04\x43har\x12\x16\n\x06length\x18\x01 \x01(\x05R\x06length\x12\x38\n\x18type_variation_reference\x18\x02 \x01(\rR\x16typeVariationReference\x1a[\n\x07VarChar\x12\x16\n\x06length\x18\x01 \x01(\x05R\x06length\x12\x38\n\x18type_variation_reference\x18\x02 \x01(\rR\x16typeVariationReference\x1a\x99\x01\n\x07\x44\x65\x63imal\x12\x19\n\x05scale\x18\x01 \x01(\x05H\x00R\x05scale\x88\x01\x01\x12!\n\tprecision\x18\x02 \x01(\x05H\x01R\tprecision\x88\x01\x01\x12\x38\n\x18type_variation_reference\x18\x03 \x01(\rR\x16typeVariationReferenceB\x08\n\x06_scaleB\x0c\n\n_precision\x1a\xff\x01\n\x0bStructField\x12\x12\n\x04name\x18\x01 \x01(\tR\x04name\x12\x34\n\tdata_type\x18\x02 \x01(\x0b\x32\x17.spark.connect.DataTypeR\x08\x64\x61taType\x12\x1a\n\x08nullable\x18\x03 \x01(\x08R\x08nullable\x12M\n\x08metadata\x18\x04 \x03(\x0b\x32\x31.spark.connect.DataType.StructField.MetadataEntryR\x08metadata\x1a;\n\rMetadataEntry\x12\x10\n\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n\x05value\x18\x02 \x01(\tR\x05value:\x02\x38\x01\x1a\x7f\n\x06Struct\x12;\n\x06\x66ields\x18\x01 \x03(\x0b\x32#.spark.connect.DataType.StructFieldR\x06\x66ields\x12\x38\n\x18type_variation_reference\x18\x02 \x01(\rR\x16typeVariationReference\x1a\xa2\x01\n\x05\x41rray\x12:\n\x0c\x65lement_type\x18\x01 \x01(\x0b\x32\x17.spark.connect.DataTypeR\x0b\x65lementType\x12#\n\rcontains_null\x18\x02 \x01(\x08R\x0c\x63ontainsNull\x12\x38\n\x18type_variation_reference\x18\x03 \x01(\rR\x16typeVariationReference\x1a\xdb\x01\n\x03Map\x12\x32\n\x08key_type\x18\x01 \x01(\x0b\x32\x17.spark.connect.DataTypeR\x07keyType\x12\x36\n\nvalue_type\x18\x02 \x01(\x0b\x32\x17.spark.connect.DataTypeR\tvalueType\x12.\n\x13value_contains_null\x18\x03 \x01(\x08R\x11valueContainsNull\x12\x38\n\x18type_variation_reference\x18\x04 \x01(\rR\x16typeVariationReferenceB\x06\n\x04kindB"\n\x1eorg.apache.spark.connect.protoP\x01\x62\x06proto3'
)


_DATATYPE = DESCRIPTOR.message_types_by_name["DataType"]
_DATATYPE_BOOLEAN = _DATATYPE.nested_types_by_name["Boolean"]
_DATATYPE_BYTE = _DATATYPE.nested_types_by_name["Byte"]
_DATATYPE_SHORT = _DATATYPE.nested_types_by_name["Short"]
_DATATYPE_INTEGER = _DATATYPE.nested_types_by_name["Integer"]
_DATATYPE_LONG = _DATATYPE.nested_types_by_name["Long"]
_DATATYPE_FLOAT = _DATATYPE.nested_types_by_name["Float"]
_DATATYPE_DOUBLE = _DATATYPE.nested_types_by_name["Double"]
_DATATYPE_STRING = _DATATYPE.nested_types_by_name["String"]
_DATATYPE_BINARY = _DATATYPE.nested_types_by_name["Binary"]
_DATATYPE_NULL = _DATATYPE.nested_types_by_name["NULL"]
_DATATYPE_TIMESTAMP = _DATATYPE.nested_types_by_name["Timestamp"]
_DATATYPE_DATE = _DATATYPE.nested_types_by_name["Date"]
_DATATYPE_TIMESTAMPNTZ = _DATATYPE.nested_types_by_name["TimestampNTZ"]
_DATATYPE_CALENDARINTERVAL = _DATATYPE.nested_types_by_name["CalendarInterval"]
_DATATYPE_YEARMONTHINTERVAL = _DATATYPE.nested_types_by_name["YearMonthInterval"]
_DATATYPE_DAYTIMEINTERVAL = _DATATYPE.nested_types_by_name["DayTimeInterval"]
_DATATYPE_CHAR = _DATATYPE.nested_types_by_name["Char"]
_DATATYPE_VARCHAR = _DATATYPE.nested_types_by_name["VarChar"]
_DATATYPE_DECIMAL = _DATATYPE.nested_types_by_name["Decimal"]
_DATATYPE_STRUCTFIELD = _DATATYPE.nested_types_by_name["StructField"]
_DATATYPE_STRUCTFIELD_METADATAENTRY = _DATATYPE_STRUCTFIELD.nested_types_by_name["MetadataEntry"]
_DATATYPE_STRUCT = _DATATYPE.nested_types_by_name["Struct"]
_DATATYPE_ARRAY = _DATATYPE.nested_types_by_name["Array"]
_DATATYPE_MAP = _DATATYPE.nested_types_by_name["Map"]
DataType = _reflection.GeneratedProtocolMessageType(
    "DataType",
    (_message.Message,),
    {
        "Boolean": _reflection.GeneratedProtocolMessageType(
            "Boolean",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_BOOLEAN,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Boolean)
            },
        ),
        "Byte": _reflection.GeneratedProtocolMessageType(
            "Byte",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_BYTE,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Byte)
            },
        ),
        "Short": _reflection.GeneratedProtocolMessageType(
            "Short",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_SHORT,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Short)
            },
        ),
        "Integer": _reflection.GeneratedProtocolMessageType(
            "Integer",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_INTEGER,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Integer)
            },
        ),
        "Long": _reflection.GeneratedProtocolMessageType(
            "Long",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_LONG,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Long)
            },
        ),
        "Float": _reflection.GeneratedProtocolMessageType(
            "Float",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_FLOAT,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Float)
            },
        ),
        "Double": _reflection.GeneratedProtocolMessageType(
            "Double",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_DOUBLE,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Double)
            },
        ),
        "String": _reflection.GeneratedProtocolMessageType(
            "String",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_STRING,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.String)
            },
        ),
        "Binary": _reflection.GeneratedProtocolMessageType(
            "Binary",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_BINARY,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Binary)
            },
        ),
        "NULL": _reflection.GeneratedProtocolMessageType(
            "NULL",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_NULL,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.NULL)
            },
        ),
        "Timestamp": _reflection.GeneratedProtocolMessageType(
            "Timestamp",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_TIMESTAMP,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Timestamp)
            },
        ),
        "Date": _reflection.GeneratedProtocolMessageType(
            "Date",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_DATE,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Date)
            },
        ),
        "TimestampNTZ": _reflection.GeneratedProtocolMessageType(
            "TimestampNTZ",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_TIMESTAMPNTZ,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.TimestampNTZ)
            },
        ),
        "CalendarInterval": _reflection.GeneratedProtocolMessageType(
            "CalendarInterval",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_CALENDARINTERVAL,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.CalendarInterval)
            },
        ),
        "YearMonthInterval": _reflection.GeneratedProtocolMessageType(
            "YearMonthInterval",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_YEARMONTHINTERVAL,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.YearMonthInterval)
            },
        ),
        "DayTimeInterval": _reflection.GeneratedProtocolMessageType(
            "DayTimeInterval",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_DAYTIMEINTERVAL,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.DayTimeInterval)
            },
        ),
        "Char": _reflection.GeneratedProtocolMessageType(
            "Char",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_CHAR,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Char)
            },
        ),
        "VarChar": _reflection.GeneratedProtocolMessageType(
            "VarChar",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_VARCHAR,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.VarChar)
            },
        ),
        "Decimal": _reflection.GeneratedProtocolMessageType(
            "Decimal",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_DECIMAL,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Decimal)
            },
        ),
        "StructField": _reflection.GeneratedProtocolMessageType(
            "StructField",
            (_message.Message,),
            {
                "MetadataEntry": _reflection.GeneratedProtocolMessageType(
                    "MetadataEntry",
                    (_message.Message,),
                    {
                        "DESCRIPTOR": _DATATYPE_STRUCTFIELD_METADATAENTRY,
                        "__module__": "spark.connect.types_pb2"
                        # @@protoc_insertion_point(class_scope:spark.connect.DataType.StructField.MetadataEntry)
                    },
                ),
                "DESCRIPTOR": _DATATYPE_STRUCTFIELD,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.StructField)
            },
        ),
        "Struct": _reflection.GeneratedProtocolMessageType(
            "Struct",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_STRUCT,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Struct)
            },
        ),
        "Array": _reflection.GeneratedProtocolMessageType(
            "Array",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_ARRAY,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Array)
            },
        ),
        "Map": _reflection.GeneratedProtocolMessageType(
            "Map",
            (_message.Message,),
            {
                "DESCRIPTOR": _DATATYPE_MAP,
                "__module__": "spark.connect.types_pb2"
                # @@protoc_insertion_point(class_scope:spark.connect.DataType.Map)
            },
        ),
        "DESCRIPTOR": _DATATYPE,
        "__module__": "spark.connect.types_pb2"
        # @@protoc_insertion_point(class_scope:spark.connect.DataType)
    },
)
_sym_db.RegisterMessage(DataType)
_sym_db.RegisterMessage(DataType.Boolean)
_sym_db.RegisterMessage(DataType.Byte)
_sym_db.RegisterMessage(DataType.Short)
_sym_db.RegisterMessage(DataType.Integer)
_sym_db.RegisterMessage(DataType.Long)
_sym_db.RegisterMessage(DataType.Float)
_sym_db.RegisterMessage(DataType.Double)
_sym_db.RegisterMessage(DataType.String)
_sym_db.RegisterMessage(DataType.Binary)
_sym_db.RegisterMessage(DataType.NULL)
_sym_db.RegisterMessage(DataType.Timestamp)
_sym_db.RegisterMessage(DataType.Date)
_sym_db.RegisterMessage(DataType.TimestampNTZ)
_sym_db.RegisterMessage(DataType.CalendarInterval)
_sym_db.RegisterMessage(DataType.YearMonthInterval)
_sym_db.RegisterMessage(DataType.DayTimeInterval)
_sym_db.RegisterMessage(DataType.Char)
_sym_db.RegisterMessage(DataType.VarChar)
_sym_db.RegisterMessage(DataType.Decimal)
_sym_db.RegisterMessage(DataType.StructField)
_sym_db.RegisterMessage(DataType.StructField.MetadataEntry)
_sym_db.RegisterMessage(DataType.Struct)
_sym_db.RegisterMessage(DataType.Array)
_sym_db.RegisterMessage(DataType.Map)

if _descriptor._USE_C_DESCRIPTORS == False:

    DESCRIPTOR._options = None
    DESCRIPTOR._serialized_options = b"\n\036org.apache.spark.connect.protoP\001"
    _DATATYPE_STRUCTFIELD_METADATAENTRY._options = None
    _DATATYPE_STRUCTFIELD_METADATAENTRY._serialized_options = b"8\001"
    _DATATYPE._serialized_start = 45
    _DATATYPE._serialized_end = 3865
    _DATATYPE_BOOLEAN._serialized_start = 1421
    _DATATYPE_BOOLEAN._serialized_end = 1488
    _DATATYPE_BYTE._serialized_start = 1490
    _DATATYPE_BYTE._serialized_end = 1554
    _DATATYPE_SHORT._serialized_start = 1556
    _DATATYPE_SHORT._serialized_end = 1621
    _DATATYPE_INTEGER._serialized_start = 1623
    _DATATYPE_INTEGER._serialized_end = 1690
    _DATATYPE_LONG._serialized_start = 1692
    _DATATYPE_LONG._serialized_end = 1756
    _DATATYPE_FLOAT._serialized_start = 1758
    _DATATYPE_FLOAT._serialized_end = 1823
    _DATATYPE_DOUBLE._serialized_start = 1825
    _DATATYPE_DOUBLE._serialized_end = 1891
    _DATATYPE_STRING._serialized_start = 1893
    _DATATYPE_STRING._serialized_end = 1959
    _DATATYPE_BINARY._serialized_start = 1961
    _DATATYPE_BINARY._serialized_end = 2027
    _DATATYPE_NULL._serialized_start = 2029
    _DATATYPE_NULL._serialized_end = 2093
    _DATATYPE_TIMESTAMP._serialized_start = 2095
    _DATATYPE_TIMESTAMP._serialized_end = 2164
    _DATATYPE_DATE._serialized_start = 2166
    _DATATYPE_DATE._serialized_end = 2230
    _DATATYPE_TIMESTAMPNTZ._serialized_start = 2232
    _DATATYPE_TIMESTAMPNTZ._serialized_end = 2304
    _DATATYPE_CALENDARINTERVAL._serialized_start = 2306
    _DATATYPE_CALENDARINTERVAL._serialized_end = 2382
    _DATATYPE_YEARMONTHINTERVAL._serialized_start = 2385
    _DATATYPE_YEARMONTHINTERVAL._serialized_end = 2564
    _DATATYPE_DAYTIMEINTERVAL._serialized_start = 2567
    _DATATYPE_DAYTIMEINTERVAL._serialized_end = 2744
    _DATATYPE_CHAR._serialized_start = 2746
    _DATATYPE_CHAR._serialized_end = 2834
    _DATATYPE_VARCHAR._serialized_start = 2836
    _DATATYPE_VARCHAR._serialized_end = 2927
    _DATATYPE_DECIMAL._serialized_start = 2930
    _DATATYPE_DECIMAL._serialized_end = 3083
    _DATATYPE_STRUCTFIELD._serialized_start = 3086
    _DATATYPE_STRUCTFIELD._serialized_end = 3341
    _DATATYPE_STRUCTFIELD_METADATAENTRY._serialized_start = 3282
    _DATATYPE_STRUCTFIELD_METADATAENTRY._serialized_end = 3341
    _DATATYPE_STRUCT._serialized_start = 3343
    _DATATYPE_STRUCT._serialized_end = 3470
    _DATATYPE_ARRAY._serialized_start = 3473
    _DATATYPE_ARRAY._serialized_end = 3635
    _DATATYPE_MAP._serialized_start = 3638
    _DATATYPE_MAP._serialized_end = 3857
# @@protoc_insertion_point(module_scope)
