/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = 'proto3';

package spark.connect;

import "spark/connect/expressions.proto";

option java_multiple_files = true;
option java_package = "org.apache.spark.connect.proto";

// The main [[Relation]] type. Fundamentally, a relation is a typed container
// that has exactly one explicit relation type set.
//
// When adding new relation types, they have to be registered here.
message Relation {
  RelationCommon common = 1;
  oneof rel_type {
    Read read = 2;
    Project project = 3;
    Filter filter = 4;
    Join join = 5;
    SetOperation set_op = 6;
    Sort sort = 7;
    Limit limit = 8;
    Aggregate aggregate = 9;
    SQL sql = 10;
    LocalRelation local_relation = 11;
    Sample sample = 12;
    Offset offset = 13;
    Deduplicate deduplicate = 14;
    Range range = 15;
    SubqueryAlias subquery_alias = 16;

    Unknown unknown = 999;
  }
}

// Used for testing purposes only.
message Unknown {}

// Common metadata of all relations.
message RelationCommon {
  string source_info = 1;
}

// Relation that uses a SQL query to generate the output.
message SQL {
  string query = 1;
}

// Relation that reads from a file / table or other data source. Does not have additional
// inputs.
message Read {
  oneof read_type {
    NamedTable named_table = 1;
    DataSource data_source = 2;
  }

  message NamedTable {
    string unparsed_identifier = 1;
  }

  message DataSource {
    // Required. Supported formats include: parquet, orc, text, json, parquet, csv, avro.
    string format = 1;
    // Optional. If not set, Spark will infer the schema.
    string schema = 2;
    // The key is case insensitive.
    map<string, string> options = 3;
  }
}

// Projection of a bag of expressions for a given input relation.
//
// The input relation must be specified.
// The projected expression can be an arbitrary expression.
message Project {
  Relation input = 1;
  repeated Expression expressions = 3;
}

// Relation that applies a boolean expression `condition` on each row of `input` to produce
// the output result.
message Filter {
  Relation input = 1;
  Expression condition = 2;
}

// Relation of type [[Join]].
//
// `left` and `right` must be present.
message Join {
  Relation left = 1;
  Relation right = 2;
  Expression join_condition = 3;
  JoinType join_type = 4;
  // Optional. using_columns provides a list of columns that should present on both sides of
  // the join inputs that this Join will join on. For example A JOIN B USING col_name is
  // equivalent to A JOIN B on A.col_name = B.col_name.
  //
  // This field does not co-exist with join_condition.
  repeated string using_columns = 5;

  enum JoinType {
    JOIN_TYPE_UNSPECIFIED = 0;
    JOIN_TYPE_INNER = 1;
    JOIN_TYPE_FULL_OUTER = 2;
    JOIN_TYPE_LEFT_OUTER = 3;
    JOIN_TYPE_RIGHT_OUTER = 4;
    JOIN_TYPE_LEFT_ANTI = 5;
    JOIN_TYPE_LEFT_SEMI = 6;
  }
}

// Relation of type [[SetOperation]]
message SetOperation {
  Relation left_input = 1;
  Relation right_input = 2;
  SetOpType set_op_type = 3;
  bool is_all = 4;
  bool by_name = 5;

  enum SetOpType {
    SET_OP_TYPE_UNSPECIFIED = 0;
    SET_OP_TYPE_INTERSECT = 1;
    SET_OP_TYPE_UNION = 2;
    SET_OP_TYPE_EXCEPT = 3;
  }
}

// Relation of type [[Limit]] that is used to `limit` rows from the input relation.
message Limit {
  Relation input = 1;
  int32 limit = 2;
}

// Relation of type [[Offset]] that is used to read rows staring from the `offset` on
// the input relation.
message Offset {
  Relation input = 1;
  int32 offset = 2;
}

// Relation of type [[Aggregate]].
message Aggregate {
  Relation input = 1;
  repeated Expression grouping_expressions = 2;
  repeated AggregateFunction result_expressions = 3;

  message AggregateFunction {
    string name = 1;
    repeated Expression arguments = 2;
  }
}

// Relation of type [[Sort]].
message Sort {
  Relation input = 1;
  repeated SortField sort_fields = 2;
  bool is_global = 3;

  message SortField {
    Expression expression = 1;
    SortDirection direction = 2;
    SortNulls nulls = 3;
  }

  enum SortDirection {
    SORT_DIRECTION_UNSPECIFIED = 0;
    SORT_DIRECTION_ASCENDING = 1;
    SORT_DIRECTION_DESCENDING = 2;
  }

  enum SortNulls {
    SORT_NULLS_UNSPECIFIED = 0;
    SORT_NULLS_FIRST = 1;
    SORT_NULLS_LAST = 2;
  }
}

// Relation of type [[Deduplicate]] which have duplicate rows removed, could consider either only
// the subset of columns or all the columns.
message Deduplicate {
  Relation input = 1;
  repeated string column_names = 2;
  bool all_columns_as_keys = 3;
}

message LocalRelation {
  repeated Expression.QualifiedAttribute attributes = 1;
  // TODO: support local data.
}

// Relation of type [[Sample]] that samples a fraction of the dataset.
message Sample {
  Relation input = 1;
  double lower_bound = 2;
  double upper_bound = 3;
  bool with_replacement = 4;
  Seed seed = 5;

  message Seed {
    int64 seed = 1;
  }
}

// Relation of type [[Range]] that generates a sequence of integers.
message Range {
  // Optional. Default value = 0
  int64 start = 1;
  // Required.
  int64 end = 2;
  // Optional. Default value = 1
  Step step = 3;
  // Optional. Default value is assigned by 1) SQL conf "spark.sql.leafNodeDefaultParallelism" if
  // it is set, or 2) spark default parallelism.
  NumPartitions num_partitions = 4;

  message Step {
    int64 step = 1;
  }

  message NumPartitions {
    int32 num_partitions = 1;
  }
}

// Relation alias.
message SubqueryAlias {
  // Required. The input relation.
  Relation input = 1;
  // Required. The alias.
  string alias = 2;
  // Optional. Qualifier of the alias.
  repeated string qualifier = 3;
}
