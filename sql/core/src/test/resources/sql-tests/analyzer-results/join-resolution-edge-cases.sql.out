-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE t1(col1 INT, col2 STRING)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
CREATE TABLE t2(col1 INT, col2 STRING)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t2`, false


-- !query
SELECT * FROM t2 as t2_1 LEFT JOIN t2 as t2_2 ON t2_1.col1 = t2_2.col1
    NATURAL JOIN t2 as t2_3
-- !query analysis
Project [col1#x, col2#x, col1#x, col2#x]
+- Project [col1#x, col2#x, col1#x, col2#x]
   +- Join Inner, ((col1#x = col1#x) AND (col2#x = col2#x))
      :- Join LeftOuter, (col1#x = col1#x)
      :  :- SubqueryAlias t2_1
      :  :  +- SubqueryAlias spark_catalog.default.t2
      :  :     +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
      :  +- SubqueryAlias t2_2
      :     +- SubqueryAlias spark_catalog.default.t2
      :        +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
      +- SubqueryAlias t2_3
         +- SubqueryAlias spark_catalog.default.t2
            +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet


-- !query
SELECT * FROM t2 as t2_1 RIGHT JOIN t2 as t2_2 ON t2_1.col1 = t2_2.col1
    NATURAL JOIN t2 as t2_3
-- !query analysis
Project [col1#x, col2#x, col1#x, col2#x]
+- Project [col1#x, col2#x, col1#x, col2#x]
   +- Join Inner, ((col1#x = col1#x) AND (col2#x = col2#x))
      :- Join RightOuter, (col1#x = col1#x)
      :  :- SubqueryAlias t2_1
      :  :  +- SubqueryAlias spark_catalog.default.t2
      :  :     +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
      :  +- SubqueryAlias t2_2
      :     +- SubqueryAlias spark_catalog.default.t2
      :        +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
      +- SubqueryAlias t2_3
         +- SubqueryAlias spark_catalog.default.t2
            +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet


-- !query
SELECT * FROM t2 as t2_1 CROSS JOIN t2 as t2_2 ON t2_1.col1 = t2_2.col1
    NATURAL JOIN t2 as t2_3
-- !query analysis
Project [col1#x, col2#x, col1#x, col2#x]
+- Project [col1#x, col2#x, col1#x, col2#x]
   +- Join Inner, ((col1#x = col1#x) AND (col2#x = col2#x))
      :- Join Cross, (col1#x = col1#x)
      :  :- SubqueryAlias t2_1
      :  :  +- SubqueryAlias spark_catalog.default.t2
      :  :     +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
      :  +- SubqueryAlias t2_2
      :     +- SubqueryAlias spark_catalog.default.t2
      :        +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
      +- SubqueryAlias t2_3
         +- SubqueryAlias spark_catalog.default.t2
            +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet


-- !query
SELECT * FROM t2 as t2_1 INNER JOIN t2 as t2_2 ON t2_1.col1 = t2_2.col1
    NATURAL JOIN t2 as t2_3
-- !query analysis
Project [col1#x, col2#x, col1#x, col2#x]
+- Project [col1#x, col2#x, col1#x, col2#x]
   +- Join Inner, ((col1#x = col1#x) AND (col2#x = col2#x))
      :- Join Inner, (col1#x = col1#x)
      :  :- SubqueryAlias t2_1
      :  :  +- SubqueryAlias spark_catalog.default.t2
      :  :     +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
      :  +- SubqueryAlias t2_2
      :     +- SubqueryAlias spark_catalog.default.t2
      :        +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
      +- SubqueryAlias t2_3
         +- SubqueryAlias spark_catalog.default.t2
            +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet


-- !query
SELECT col2 AS alias FROM t1 as t1_1 LEFT ANTI JOIN t1 as t1_2 ON t1_1.col1 = t1_2.col1 ORDER BY col2
-- !query analysis
Project [alias#x]
+- Sort [col2#x ASC NULLS FIRST], true
   +- Project [col2#x AS alias#x, col2#x]
      +- Join LeftAnti, (col1#x = col1#x)
         :- SubqueryAlias t1_1
         :  +- SubqueryAlias spark_catalog.default.t1
         :     +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
         +- SubqueryAlias t1_2
            +- SubqueryAlias spark_catalog.default.t1
               +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet


-- !query
SELECT col2 AS alias FROM t1 as t1_1 LEFT SEMI JOIN t1 as t1_2 ON t1_1.col1 = t1_2.col1 ORDER BY col2
-- !query analysis
Project [alias#x]
+- Sort [col2#x ASC NULLS FIRST], true
   +- Project [col2#x AS alias#x, col2#x]
      +- Join LeftSemi, (col1#x = col1#x)
         :- SubqueryAlias t1_1
         :  +- SubqueryAlias spark_catalog.default.t1
         :     +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
         +- SubqueryAlias t1_2
            +- SubqueryAlias spark_catalog.default.t1
               +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet


-- !query
SELECT col1 FROM t1 as t1_1 LEFT SEMI JOIN t1 as t1_2 ORDER BY col2
-- !query analysis
Project [col1#x]
+- Sort [col2#x ASC NULLS FIRST], true
   +- Project [col1#x, col2#x]
      +- Join LeftSemi
         :- SubqueryAlias t1_1
         :  +- SubqueryAlias spark_catalog.default.t1
         :     +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
         +- SubqueryAlias t1_2
            +- SubqueryAlias spark_catalog.default.t1
               +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet


-- !query
SELECT col1 FROM t1 as t1_1 LEFT SEMI JOIN t1 as t1_2 GROUP BY ALL HAVING MIN(col2) > 1
-- !query analysis
Project [col1#x]
+- Filter (cast(min(col2)#x as bigint) > cast(1 as bigint))
   +- Aggregate [col1#x], [col1#x, min(col2#x) AS min(col2)#x]
      +- Join LeftSemi
         :- SubqueryAlias t1_1
         :  +- SubqueryAlias spark_catalog.default.t1
         :     +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
         +- SubqueryAlias t1_2
            +- SubqueryAlias spark_catalog.default.t1
               +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet


-- !query
SELECT 1 FROM t2 NATURAL JOIN t1 JOIN t2 ON t2.col1 = t1.col1 WHERE t2.col2 = 1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`t2`.`col1`",
    "referenceNames" : "[`spark_catalog`.`default`.`t2`.`col1`, `spark_catalog`.`default`.`t2`.`col1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 45,
    "stopIndex" : 51,
    "fragment" : "t2.col1"
  } ]
}


-- !query
SELECT 1 FROM t2 NATURAL JOIN t1 JOIN t2 ON t2.col1 = t1.col1 GROUP BY t2.col2 HAVING t2.col2 = 1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`t2`.`col1`",
    "referenceNames" : "[`spark_catalog`.`default`.`t2`.`col1`, `spark_catalog`.`default`.`t2`.`col1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 45,
    "stopIndex" : 51,
    "fragment" : "t2.col1"
  } ]
}


-- !query
SELECT 1 FROM t2 NATURAL JOIN t1 JOIN t2 ON t2.col1 = t1.col1 ORDER BY t2.col2
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`t2`.`col1`",
    "referenceNames" : "[`spark_catalog`.`default`.`t2`.`col1`, `spark_catalog`.`default`.`t2`.`col1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 45,
    "stopIndex" : 51,
    "fragment" : "t2.col1"
  } ]
}


-- !query
DROP TABLE t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
DROP TABLE t2
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t2
