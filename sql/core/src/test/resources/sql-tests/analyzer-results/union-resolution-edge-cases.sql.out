-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE t1(col1 TIMESTAMP, col2 STRING)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
CREATE TABLE t2(col1 INT, col2 STRING)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t2`, false


-- !query
WITH cte AS (
    SELECT col1, col1 FROM t1
    UNION
    SELECT col1, col1 FROM t1
)
SELECT col1 FROM cte
-- !query analysis
WithCTE
:- CTERelationDef xxxx, false
:  +- SubqueryAlias cte
:     +- Distinct
:        +- Union false, false
:           :- Project [col1#x, col1#x AS col1#x]
:           :  +- Project [col1#x, col1#x]
:           :     +- SubqueryAlias spark_catalog.default.t1
:           :        +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
:           +- Project [col1#x, col1#x AS col1#x]
:              +- Project [col1#x, col1#x]
:                 +- SubqueryAlias spark_catalog.default.t1
:                    +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
+- Project [col1#x]
   +- SubqueryAlias cte
      +- CTERelationRef xxxx, true, [col1#x, col1#x], false, false


-- !query
WITH cte AS (
    SELECT col2, from_utc_timestamp(col1, 'unknown'), col2 FROM t1
    UNION ALL
    SELECT col2, from_utc_timestamp(col1, 'unknown'), col2 FROM t1
)
SELECT * FROM cte
-- !query analysis
WithCTE
:- CTERelationDef xxxx, false
:  +- SubqueryAlias cte
:     +- Union false, false
:        :- Project [col2#x, from_utc_timestamp(col1, unknown)#x, col2#x AS col2#x]
:        :  +- Project [col2#x, from_utc_timestamp(col1#x, unknown) AS from_utc_timestamp(col1, unknown)#x, col2#x]
:        :     +- SubqueryAlias spark_catalog.default.t1
:        :        +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
:        +- Project [col2#x, from_utc_timestamp(col1, unknown)#x, col2#x AS col2#x]
:           +- Project [col2#x, from_utc_timestamp(col1#x, unknown) AS from_utc_timestamp(col1, unknown)#x, col2#x]
:              +- SubqueryAlias spark_catalog.default.t1
:                 +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
+- Project [col2#x, from_utc_timestamp(col1, unknown)#x, col2#x]
   +- SubqueryAlias cte
      +- CTERelationRef xxxx, true, [col2#x, from_utc_timestamp(col1, unknown)#x, col2#x], false, false


-- !query
SELECT col1 FROM t3 WHERE (col1, col1) IN (SELECT col1, col1 UNION SELECT col1, col1)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`t3`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 18,
    "stopIndex" : 19,
    "fragment" : "t3"
  } ]
}


-- !query
SELECT col1, TRIM(col2), col1 FROM t2 UNION SELECT col1, col2, col1 FROM t2
-- !query analysis
Distinct
+- Union false, false
   :- Project [col1#x, trim(col2)#x, col1#x AS col1#x]
   :  +- Project [col1#x, trim(col2#x, None) AS trim(col2)#x, col1#x]
   :     +- SubqueryAlias spark_catalog.default.t2
   :        +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
   +- Project [col1#x, col2#x, col1#x AS col1#x]
      +- Project [col1#x, col2#x, col1#x]
         +- SubqueryAlias spark_catalog.default.t2
            +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet


-- !query
SELECT col1, TRIM(col2), col1 FROM t2 MINUS SELECT col1, col2, col1 FROM t2
-- !query analysis
Except false
:- Project [col1#x, trim(col2#x, None) AS trim(col2)#x, col1#x]
:  +- SubqueryAlias spark_catalog.default.t2
:     +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
+- Project [col1#x, col2#x, col1#x]
   +- SubqueryAlias spark_catalog.default.t2
      +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet


-- !query
SELECT col1, LTRIM(col2), col1 FROM t2 MINUS SELECT col1, col2, col1 FROM t2
-- !query analysis
Except false
:- Project [col1#x, ltrim(col2#x, None) AS ltrim(col2)#x, col1#x]
:  +- SubqueryAlias spark_catalog.default.t2
:     +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
+- Project [col1#x, col2#x, col1#x]
   +- SubqueryAlias spark_catalog.default.t2
      +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet


-- !query
SELECT col1, RTRIM(col2), col1 FROM t2 EXCEPT SELECT col1, col2, col1 FROM t2
-- !query analysis
Except false
:- Project [col1#x, rtrim(col2#x, None) AS rtrim(col2)#x, col1#x]
:  +- SubqueryAlias spark_catalog.default.t2
:     +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
+- Project [col1#x, col2#x, col1#x]
   +- SubqueryAlias spark_catalog.default.t2
      +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet


-- !query
SELECT col1, LOWER(col2), col1 FROM t2 INTERSECT SELECT col1, col2, col1 FROM t2
-- !query analysis
Intersect false
:- Project [col1#x, lower(col2#x) AS lower(col2)#x, col1#x]
:  +- SubqueryAlias spark_catalog.default.t2
:     +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet
+- Project [col1#x, col2#x, col1#x]
   +- SubqueryAlias spark_catalog.default.t2
      +- Relation spark_catalog.default.t2[col1#x,col2#x] parquet


-- !query
DROP TABLE t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
DROP TABLE t2
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t2
