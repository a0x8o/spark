-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE t1(col1 INT, col2 STRING)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
CREATE TABLE t2(col1 INT)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t2`, false


-- !query
CREATE TABLE t3(col1 INT, col2 STRING)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t3`, false


-- !query
SELECT *
FROM (
    SELECT (
        SELECT t1.col1
        FROM t1
        WHERE t3.col1 = t1.col2
        LIMIT 1
    )
    FROM t3
    GROUP BY (
        SELECT t1.col1
        FROM t1
        WHERE t3.col1 = t1.col2
        LIMIT 1
    )
)
-- !query analysis
Project [scalarsubquery(col1)#x]
+- SubqueryAlias __auto_generated_subquery_name
   +- Aggregate [scalar-subquery#x [col1#x]], [scalar-subquery#x [col1#x] AS scalarsubquery(col1)#x]
      :  :- GlobalLimit 1
      :  :  +- LocalLimit 1
      :  :     +- Project [col1#x]
      :  :        +- Filter (cast(outer(col1#x) as bigint) = cast(col2#x as bigint))
      :  :           +- SubqueryAlias spark_catalog.default.t1
      :  :              +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
      :  +- GlobalLimit 1
      :     +- LocalLimit 1
      :        +- Project [col1#x]
      :           +- Filter (cast(outer(col1#x) as bigint) = cast(col2#x as bigint))
      :              +- SubqueryAlias spark_catalog.default.t1
      :                 +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
      +- SubqueryAlias spark_catalog.default.t3
         +- Relation spark_catalog.default.t3[col1#x,col2#x] parquet


-- !query
SELECT *
FROM (
    SELECT 1 IN (
        SELECT t1.col1
        FROM t1
        WHERE t3.col1 = t1.col2
        LIMIT 1
    )
    FROM t3
    GROUP BY 1 IN (
        SELECT t1.col1
        FROM t1
        WHERE t3.col1 = t1.col2
        LIMIT 1
    )
)
-- !query analysis
Project [(1 IN (listquery(col1)))#x]
+- SubqueryAlias __auto_generated_subquery_name
   +- Aggregate [1 IN (list#x [col1#x])], [1 IN (list#x [col1#x]) AS (1 IN (listquery(col1)))#x]
      :  :- GlobalLimit 1
      :  :  +- LocalLimit 1
      :  :     +- Project [col1#x]
      :  :        +- Filter (cast(outer(col1#x) as bigint) = cast(col2#x as bigint))
      :  :           +- SubqueryAlias spark_catalog.default.t1
      :  :              +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
      :  +- GlobalLimit 1
      :     +- LocalLimit 1
      :        +- Project [col1#x]
      :           +- Filter (cast(outer(col1#x) as bigint) = cast(col2#x as bigint))
      :              +- SubqueryAlias spark_catalog.default.t1
      :                 +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
      +- SubqueryAlias spark_catalog.default.t3
         +- Relation spark_catalog.default.t3[col1#x,col2#x] parquet


-- !query
SELECT *
FROM (
    SELECT EXISTS (
        SELECT t1.col1
        FROM t1
        WHERE t3.col1 = t1.col2
        LIMIT 1
    )
    FROM t3
    GROUP BY EXISTS (
        SELECT t1.col1
        FROM t1
        WHERE t3.col1 = t1.col2
        LIMIT 1
    )
)
-- !query analysis
Project [exists(col1)#x]
+- SubqueryAlias __auto_generated_subquery_name
   +- Aggregate [exists#x [col1#x]], [exists#x [col1#x] AS exists(col1)#x]
      :  :- GlobalLimit 1
      :  :  +- LocalLimit 1
      :  :     +- Project [col1#x]
      :  :        +- Filter (cast(outer(col1#x) as bigint) = cast(col2#x as bigint))
      :  :           +- SubqueryAlias spark_catalog.default.t1
      :  :              +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
      :  +- GlobalLimit 1
      :     +- LocalLimit 1
      :        +- Project [col1#x]
      :           +- Filter (cast(outer(col1#x) as bigint) = cast(col2#x as bigint))
      :              +- SubqueryAlias spark_catalog.default.t1
      :                 +- Relation spark_catalog.default.t1[col1#x,col2#x] parquet
      +- SubqueryAlias spark_catalog.default.t3
         +- Relation spark_catalog.default.t3[col1#x,col2#x] parquet


-- !query
SELECT col1 IN (SELECT col1 FROM t2)
FROM t2
GROUP BY col1 IN (SELECT col1 FROM t2), col1
ORDER BY col1 IN (SELECT col1 FROM t2)
-- !query analysis
Sort [(col1 IN (listquery()))#x ASC NULLS FIRST], true
+- Aggregate [col1#x IN (list#x []), col1#x], [col1#x IN (list#x []) AS (col1 IN (listquery()))#x]
   :  :- Project [col1#x]
   :  :  +- SubqueryAlias spark_catalog.default.t2
   :  :     +- Relation spark_catalog.default.t2[col1#x] parquet
   :  +- Project [col1#x]
   :     +- SubqueryAlias spark_catalog.default.t2
   :        +- Relation spark_catalog.default.t2[col1#x] parquet
   +- SubqueryAlias spark_catalog.default.t2
      +- Relation spark_catalog.default.t2[col1#x] parquet


-- !query
SELECT col1 FROM t2 GROUP BY col1 IN (SELECT col1 FROM t2), col1 ORDER BY col1 IN (SELECT col1 FROM t2)
-- !query analysis
Project [col1#x]
+- Sort [(col1 IN (listquery()))#x ASC NULLS FIRST], true
   +- Aggregate [col1#x IN (list#x []), col1#x], [col1#x, col1#x IN (list#x []) AS (col1 IN (listquery()))#x]
      :  :- Project [col1#x]
      :  :  +- SubqueryAlias spark_catalog.default.t2
      :  :     +- Relation spark_catalog.default.t2[col1#x] parquet
      :  +- Project [col1#x]
      :     +- SubqueryAlias spark_catalog.default.t2
      :        +- Relation spark_catalog.default.t2[col1#x] parquet
      +- SubqueryAlias spark_catalog.default.t2
         +- Relation spark_catalog.default.t2[col1#x] parquet


-- !query
SELECT col1 FROM t2 GROUP BY col1 ORDER BY 1 IN (SELECT 1)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.UNSUPPORTED_IN_EXISTS_SUBQUERY",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Sort [1 IN (list#x []) ASC NULLS FIRST], true\n:  +- Project [1 AS 1#x]\n:     +- OneRowRelation\n+- Aggregate [col1#x], [col1#x]\n   +- SubqueryAlias spark_catalog.default.t2\n      +- Relation spark_catalog.default.t2[col1#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 46,
    "stopIndex" : 58,
    "fragment" : "IN (SELECT 1)"
  } ]
}


-- !query
SELECT col1 AS a, a + 1 FROM t2 GROUP BY col1 ORDER BY 1 IN (SELECT 1)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.UNSUPPORTED_IN_EXISTS_SUBQUERY",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Sort [1 IN (list#x []) ASC NULLS FIRST], true\n:  +- Project [1 AS 1#x]\n:     +- OneRowRelation\n+- Project [a#x, (a#x + 1) AS (lateralAliasReference(a) + 1)#x]\n   +- Project [col1#x, col1#x AS a#x]\n      +- Aggregate [col1#x], [col1#x]\n         +- SubqueryAlias spark_catalog.default.t2\n            +- Relation spark_catalog.default.t2[col1#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 58,
    "stopIndex" : 70,
    "fragment" : "IN (SELECT 1)"
  } ]
}


-- !query
DROP TABLE t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
DROP TABLE t2
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t2


-- !query
DROP TABLE t3
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t3
