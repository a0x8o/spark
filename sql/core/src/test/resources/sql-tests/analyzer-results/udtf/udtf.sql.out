-- Automatically generated by SQLQueryTestSuite
-- !query
DROP VIEW IF EXISTS t1
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`t1`, true, true, false


-- !query
DROP VIEW IF EXISTS t2
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`t2`, true, true, false


-- !query
CREATE OR REPLACE TEMPORARY VIEW t1 AS VALUES (0, 1), (1, 2) t(c1, c2)
-- !query analysis
CreateViewCommand `t1`, VALUES (0, 1), (1, 2) t(c1, c2), false, true, LocalTempView, true
   +- SubqueryAlias t
      +- LocalRelation [c1#x, c2#x]


-- !query
CREATE OR REPLACE TEMPORARY VIEW t2 AS VALUES (0, 1), (1, 2), (1, 3) t(partition_col, input)
-- !query analysis
CreateViewCommand `t2`, VALUES (0, 1), (1, 2), (1, 3) t(partition_col, input), false, true, LocalTempView, true
   +- SubqueryAlias t
      +- LocalRelation [partition_col#x, input#x]


-- !query
SELECT * FROM udtf(1, 2)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM udtf(-1, 0)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM udtf(0, -1)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM udtf(0, 0)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT a, b FROM udtf(1, 2) t(a, b)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM t1, LATERAL udtf(c1, c2)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM t1 LEFT JOIN LATERAL udtf(c1, c2)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM udtf(1, 2) t(c1, c2), LATERAL udtf(c1, c2)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM udtf(cast(rand(0) AS int) + 1, 1)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM UDTFCountSumLast(TABLE(t2) WITH SINGLE PARTITION)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM UDTFCountSumLast(TABLE(t2) PARTITION BY partition_col ORDER BY input)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM UDTFCountSumLast(TABLE(t2) PARTITION BY partition_col ORDER BY input DESC)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM
    VALUES (0), (1) AS t(col)
    JOIN LATERAL
    UDTFCountSumLast(TABLE(t2) PARTITION BY partition_col ORDER BY input DESC)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.NON_DETERMINISTIC_LATERAL_SUBQUERIES",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "LateralJoin lateral-subquery#x [], Inner\n:  +- Project [count#x, total#x, last#x]\n:     +- LateralJoin lateral-subquery#x [c#x], Inner\n:        :  +- SubqueryAlias __auto_generated_subquery_name_1\n:        :     +- Generate UDTFCountSumLast(outer(c#x))#x, false, [count#x, total#x, last#x]\n:        :        +- OneRowRelation\n:        +- SubqueryAlias __auto_generated_subquery_name_0\n:           +- Project [named_struct(partition_col, partition_col#x, input, input#x, partition_by_0, partition_by_0#x) AS c#x]\n:              +- Sort [partition_by_0#x ASC NULLS FIRST, input#x DESC NULLS LAST], false\n:                 +- RepartitionByExpression [partition_by_0#x]\n:                    +- Project [partition_col#x, input#x, partition_col#x AS partition_by_0#x]\n:                       +- SubqueryAlias t2\n:                          +- View (`t2`, [partition_col#x,input#x])\n:                             +- Project [cast(partition_col#x as int) AS partition_col#x, cast(input#x as int) AS input#x]\n:                                +- SubqueryAlias t\n:                                   +- LocalRelation [partition_col#x, input#x]\n+- SubqueryAlias t\n   +- LocalRelation [col#x]\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 49,
    "stopIndex" : 139,
    "fragment" : "JOIN LATERAL\n    UDTFCountSumLast(TABLE(t2) PARTITION BY partition_col ORDER BY input DESC)"
  } ]
}


-- !query
SELECT * FROM UDTFWithSinglePartition(TABLE(t2))
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM UDTFWithSinglePartition(TABLE(t2) WITH SINGLE PARTITION)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INCOMPATIBLE_WITH_CALL",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFWithSinglePartition",
    "invalidFunctionCallProperty" : "specified the WITH SINGLE PARTITION or PARTITION BY clause; please remove these clauses and retry the query again.",
    "requestedMetadata" : "specified its own required partitioning of the input table"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 70,
    "fragment" : "UDTFWithSinglePartition(TABLE(t2) WITH SINGLE PARTITION)"
  } ]
}


-- !query
SELECT * FROM UDTFWithSinglePartition(TABLE(t2) PARTITION BY partition_col)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INCOMPATIBLE_WITH_CALL",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFWithSinglePartition",
    "invalidFunctionCallProperty" : "specified the WITH SINGLE PARTITION or PARTITION BY clause; please remove these clauses and retry the query again.",
    "requestedMetadata" : "specified its own required partitioning of the input table"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 75,
    "fragment" : "UDTFWithSinglePartition(TABLE(t2) PARTITION BY partition_col)"
  } ]
}


-- !query
SELECT * FROM
    VALUES (0), (1) AS t(col)
    JOIN LATERAL
    UDTFWithSinglePartition(TABLE(t2) PARTITION BY partition_col)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INCOMPATIBLE_WITH_CALL",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFWithSinglePartition",
    "invalidFunctionCallProperty" : "specified the WITH SINGLE PARTITION or PARTITION BY clause; please remove these clauses and retry the query again.",
    "requestedMetadata" : "specified its own required partitioning of the input table"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 66,
    "stopIndex" : 126,
    "fragment" : "UDTFWithSinglePartition(TABLE(t2) PARTITION BY partition_col)"
  } ]
}


-- !query
SELECT * FROM UDTFPartitionByOrderBy(TABLE(t2))
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT * FROM UDTFPartitionByOrderBy(TABLE(t2) WITH SINGLE PARTITION)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INCOMPATIBLE_WITH_CALL",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFPartitionByOrderBy",
    "invalidFunctionCallProperty" : "specified the WITH SINGLE PARTITION or PARTITION BY clause; please remove these clauses and retry the query again.",
    "requestedMetadata" : "specified its own required partitioning of the input table"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 69,
    "fragment" : "UDTFPartitionByOrderBy(TABLE(t2) WITH SINGLE PARTITION)"
  } ]
}


-- !query
SELECT * FROM UDTFPartitionByOrderBy(TABLE(t2) PARTITION BY partition_col)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INCOMPATIBLE_WITH_CALL",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFPartitionByOrderBy",
    "invalidFunctionCallProperty" : "specified the WITH SINGLE PARTITION or PARTITION BY clause; please remove these clauses and retry the query again.",
    "requestedMetadata" : "specified its own required partitioning of the input table"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 74,
    "fragment" : "UDTFPartitionByOrderBy(TABLE(t2) PARTITION BY partition_col)"
  } ]
}


-- !query
SELECT * FROM
    VALUES (0), (1) AS t(col)
    JOIN LATERAL
    UDTFPartitionByOrderBy(TABLE(t2) PARTITION BY partition_col)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INCOMPATIBLE_WITH_CALL",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFPartitionByOrderBy",
    "invalidFunctionCallProperty" : "specified the WITH SINGLE PARTITION or PARTITION BY clause; please remove these clauses and retry the query again.",
    "requestedMetadata" : "specified its own required partitioning of the input table"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 66,
    "stopIndex" : 125,
    "fragment" : "UDTFPartitionByOrderBy(TABLE(t2) PARTITION BY partition_col)"
  } ]
}


-- !query
SELECT * FROM UDTFInvalidPartitionByAndWithSinglePartition(TABLE(t2))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INVALID",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFInvalidPartitionByAndWithSinglePartition",
    "reason" : "the 'with_single_partition' field cannot be assigned to true if the 'partition_by' list is non-empty"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 69,
    "fragment" : "UDTFInvalidPartitionByAndWithSinglePartition(TABLE(t2))"
  } ]
}


-- !query
SELECT * FROM UDTFInvalidPartitionByAndWithSinglePartition(TABLE(t2) WITH SINGLE PARTITION)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INVALID",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFInvalidPartitionByAndWithSinglePartition",
    "reason" : "the 'with_single_partition' field cannot be assigned to true if the 'partition_by' list is non-empty"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 91,
    "fragment" : "UDTFInvalidPartitionByAndWithSinglePartition(TABLE(t2) WITH SINGLE PARTITION)"
  } ]
}


-- !query
SELECT * FROM UDTFInvalidPartitionByAndWithSinglePartition(TABLE(t2) PARTITION BY partition_col)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INVALID",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFInvalidPartitionByAndWithSinglePartition",
    "reason" : "the 'with_single_partition' field cannot be assigned to true if the 'partition_by' list is non-empty"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 96,
    "fragment" : "UDTFInvalidPartitionByAndWithSinglePartition(TABLE(t2) PARTITION BY partition_col)"
  } ]
}


-- !query
SELECT * FROM
    VALUES (0), (1) AS t(col)
    JOIN LATERAL
    UDTFInvalidPartitionByAndWithSinglePartition(TABLE(t2) PARTITION BY partition_col)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INVALID",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFInvalidPartitionByAndWithSinglePartition",
    "reason" : "the 'with_single_partition' field cannot be assigned to true if the 'partition_by' list is non-empty"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 66,
    "stopIndex" : 147,
    "fragment" : "UDTFInvalidPartitionByAndWithSinglePartition(TABLE(t2) PARTITION BY partition_col)"
  } ]
}


-- !query
SELECT * FROM UDTFInvalidOrderByWithoutPartitionBy(TABLE(t2))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INVALID",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFInvalidOrderByWithoutPartitionBy",
    "reason" : "the 'order_by' field cannot be non-empty unless the 'with_single_partition' field is set to true or the 'partition_by' list is non-empty"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 61,
    "fragment" : "UDTFInvalidOrderByWithoutPartitionBy(TABLE(t2))"
  } ]
}


-- !query
SELECT * FROM UDTFInvalidOrderByWithoutPartitionBy(TABLE(t2) WITH SINGLE PARTITION)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INVALID",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFInvalidOrderByWithoutPartitionBy",
    "reason" : "the 'order_by' field cannot be non-empty unless the 'with_single_partition' field is set to true or the 'partition_by' list is non-empty"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 83,
    "fragment" : "UDTFInvalidOrderByWithoutPartitionBy(TABLE(t2) WITH SINGLE PARTITION)"
  } ]
}


-- !query
SELECT * FROM UDTFInvalidOrderByWithoutPartitionBy(TABLE(t2) PARTITION BY partition_col)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INVALID",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFInvalidOrderByWithoutPartitionBy",
    "reason" : "the 'order_by' field cannot be non-empty unless the 'with_single_partition' field is set to true or the 'partition_by' list is non-empty"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 88,
    "fragment" : "UDTFInvalidOrderByWithoutPartitionBy(TABLE(t2) PARTITION BY partition_col)"
  } ]
}


-- !query
SELECT * FROM
    VALUES (0), (1) AS t(col)
    JOIN LATERAL
    UDTFInvalidOrderByWithoutPartitionBy(TABLE(t2) PARTITION BY partition_col)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "TABLE_VALUED_FUNCTION_REQUIRED_METADATA_INVALID",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "UDTFInvalidOrderByWithoutPartitionBy",
    "reason" : "the 'order_by' field cannot be non-empty unless the 'with_single_partition' field is set to true or the 'partition_by' list is non-empty"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 66,
    "stopIndex" : 139,
    "fragment" : "UDTFInvalidOrderByWithoutPartitionBy(TABLE(t2) PARTITION BY partition_col)"
  } ]
}


-- !query
DROP VIEW t1
-- !query analysis
DropTempViewCommand t1


-- !query
DROP VIEW t2
-- !query analysis
DropTempViewCommand t2
