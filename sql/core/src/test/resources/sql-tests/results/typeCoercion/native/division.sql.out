-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW t AS SELECT 1
-- !query schema
struct<>
-- !query output



-- !query
SELECT cast(1 as tinyint) / cast(1 as tinyint) FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) / CAST(1 AS TINYINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as tinyint) / cast(1 as smallint) FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) / CAST(1 AS SMALLINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as tinyint) / cast(1 as int) FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) / CAST(1 AS INT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as tinyint) / cast(1 as bigint) FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) / CAST(1 AS BIGINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as tinyint) / cast(1 as float) FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) / CAST(1 AS FLOAT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as tinyint) / cast(1 as double) FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) / CAST(1 AS DOUBLE)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as tinyint) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) / CAST(1 AS DECIMAL(10,0))):decimal(14,11)>
-- !query output
1.00000000000


-- !query
SELECT cast(1 as tinyint) / cast(1 as string) FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) / CAST(1 AS STRING)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as tinyint) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS TINYINT) / CAST(1 AS BINARY))\"",
    "left" : "\"TINYINT\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 54,
    "fragment" : "SELECT cast(1 as tinyint) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast(1 as tinyint) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS TINYINT) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"TINYINT\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 53,
    "fragment" : "SELECT cast(1 as tinyint) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast(1 as tinyint) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS TINYINT) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"TINYINT\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 77,
    "fragment" : "SELECT cast(1 as tinyint) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast(1 as tinyint) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS TINYINT) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"TINYINT\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 70,
    "fragment" : "SELECT cast(1 as tinyint) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast(1 as smallint) / cast(1 as tinyint) FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) / CAST(1 AS TINYINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as smallint) / cast(1 as smallint) FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) / CAST(1 AS SMALLINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as smallint) / cast(1 as int) FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) / CAST(1 AS INT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as smallint) / cast(1 as bigint) FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) / CAST(1 AS BIGINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as smallint) / cast(1 as float) FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) / CAST(1 AS FLOAT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as smallint) / cast(1 as double) FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) / CAST(1 AS DOUBLE)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as smallint) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) / CAST(1 AS DECIMAL(10,0))):decimal(16,11)>
-- !query output
1.00000000000


-- !query
SELECT cast(1 as smallint) / cast(1 as string) FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) / CAST(1 AS STRING)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as smallint) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS SMALLINT) / CAST(1 AS BINARY))\"",
    "left" : "\"SMALLINT\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 55,
    "fragment" : "SELECT cast(1 as smallint) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast(1 as smallint) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS SMALLINT) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"SMALLINT\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 54,
    "fragment" : "SELECT cast(1 as smallint) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast(1 as smallint) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS SMALLINT) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"SMALLINT\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 78,
    "fragment" : "SELECT cast(1 as smallint) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast(1 as smallint) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS SMALLINT) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"SMALLINT\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 71,
    "fragment" : "SELECT cast(1 as smallint) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast(1 as int) / cast(1 as tinyint) FROM t
-- !query schema
struct<(CAST(1 AS INT) / CAST(1 AS TINYINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as int) / cast(1 as smallint) FROM t
-- !query schema
struct<(CAST(1 AS INT) / CAST(1 AS SMALLINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as int) / cast(1 as int) FROM t
-- !query schema
struct<(CAST(1 AS INT) / CAST(1 AS INT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as int) / cast(1 as bigint) FROM t
-- !query schema
struct<(CAST(1 AS INT) / CAST(1 AS BIGINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as int) / cast(1 as float) FROM t
-- !query schema
struct<(CAST(1 AS INT) / CAST(1 AS FLOAT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as int) / cast(1 as double) FROM t
-- !query schema
struct<(CAST(1 AS INT) / CAST(1 AS DOUBLE)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as int) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<(CAST(1 AS INT) / CAST(1 AS DECIMAL(10,0))):decimal(21,11)>
-- !query output
1.00000000000


-- !query
SELECT cast(1 as int) / cast(1 as string) FROM t
-- !query schema
struct<(CAST(1 AS INT) / CAST(1 AS STRING)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as int) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS INT) / CAST(1 AS BINARY))\"",
    "left" : "\"INT\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 50,
    "fragment" : "SELECT cast(1 as int) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast(1 as int) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS INT) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"INT\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 49,
    "fragment" : "SELECT cast(1 as int) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast(1 as int) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS INT) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"INT\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 73,
    "fragment" : "SELECT cast(1 as int) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast(1 as int) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS INT) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"INT\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 66,
    "fragment" : "SELECT cast(1 as int) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast(1 as bigint) / cast(1 as tinyint) FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) / CAST(1 AS TINYINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as bigint) / cast(1 as smallint) FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) / CAST(1 AS SMALLINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as bigint) / cast(1 as int) FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) / CAST(1 AS INT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as bigint) / cast(1 as bigint) FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) / CAST(1 AS BIGINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as bigint) / cast(1 as float) FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) / CAST(1 AS FLOAT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as bigint) / cast(1 as double) FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) / CAST(1 AS DOUBLE)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as bigint) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) / CAST(1 AS DECIMAL(10,0))):decimal(31,11)>
-- !query output
1.00000000000


-- !query
SELECT cast(1 as bigint) / cast(1 as string) FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) / CAST(1 AS STRING)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as bigint) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BIGINT) / CAST(1 AS BINARY))\"",
    "left" : "\"BIGINT\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 53,
    "fragment" : "SELECT cast(1 as bigint) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast(1 as bigint) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BIGINT) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"BIGINT\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 52,
    "fragment" : "SELECT cast(1 as bigint) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast(1 as bigint) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BIGINT) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"BIGINT\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 76,
    "fragment" : "SELECT cast(1 as bigint) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast(1 as bigint) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BIGINT) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"BIGINT\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 69,
    "fragment" : "SELECT cast(1 as bigint) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast(1 as float) / cast(1 as tinyint) FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) / CAST(1 AS TINYINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as float) / cast(1 as smallint) FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) / CAST(1 AS SMALLINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as float) / cast(1 as int) FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) / CAST(1 AS INT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as float) / cast(1 as bigint) FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) / CAST(1 AS BIGINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as float) / cast(1 as float) FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) / CAST(1 AS FLOAT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as float) / cast(1 as double) FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) / CAST(1 AS DOUBLE)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as float) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) / CAST(1 AS DECIMAL(10,0))):double>
-- !query output
1.0


-- !query
SELECT cast(1 as float) / cast(1 as string) FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) / CAST(1 AS STRING)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as float) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS FLOAT) / CAST(1 AS BINARY))\"",
    "left" : "\"FLOAT\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 52,
    "fragment" : "SELECT cast(1 as float) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast(1 as float) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS FLOAT) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"FLOAT\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 51,
    "fragment" : "SELECT cast(1 as float) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast(1 as float) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS FLOAT) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"FLOAT\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 75,
    "fragment" : "SELECT cast(1 as float) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast(1 as float) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS FLOAT) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"FLOAT\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 68,
    "fragment" : "SELECT cast(1 as float) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast(1 as double) / cast(1 as tinyint) FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) / CAST(1 AS TINYINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as double) / cast(1 as smallint) FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) / CAST(1 AS SMALLINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as double) / cast(1 as int) FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) / CAST(1 AS INT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as double) / cast(1 as bigint) FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) / CAST(1 AS BIGINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as double) / cast(1 as float) FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) / CAST(1 AS FLOAT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as double) / cast(1 as double) FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) / CAST(1 AS DOUBLE)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as double) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) / CAST(1 AS DECIMAL(10,0))):double>
-- !query output
1.0


-- !query
SELECT cast(1 as double) / cast(1 as string) FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) / CAST(1 AS STRING)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as double) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS DOUBLE) / CAST(1 AS BINARY))\"",
    "left" : "\"DOUBLE\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 53,
    "fragment" : "SELECT cast(1 as double) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast(1 as double) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS DOUBLE) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"DOUBLE\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 52,
    "fragment" : "SELECT cast(1 as double) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast(1 as double) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS DOUBLE) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"DOUBLE\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 76,
    "fragment" : "SELECT cast(1 as double) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast(1 as double) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS DOUBLE) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"DOUBLE\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 69,
    "fragment" : "SELECT cast(1 as double) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast(1 as decimal(10, 0)) / cast(1 as tinyint) FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) / CAST(1 AS TINYINT)):decimal(16,6)>
-- !query output
1.000000


-- !query
SELECT cast(1 as decimal(10, 0)) / cast(1 as smallint) FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) / CAST(1 AS SMALLINT)):decimal(16,6)>
-- !query output
1.000000


-- !query
SELECT cast(1 as decimal(10, 0)) / cast(1 as int) FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) / CAST(1 AS INT)):decimal(21,11)>
-- !query output
1.00000000000


-- !query
SELECT cast(1 as decimal(10, 0)) / cast(1 as bigint) FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) / CAST(1 AS BIGINT)):decimal(31,21)>
-- !query output
1.000000000000000000000


-- !query
SELECT cast(1 as decimal(10, 0)) / cast(1 as float) FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) / CAST(1 AS FLOAT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as decimal(10, 0)) / cast(1 as double) FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) / CAST(1 AS DOUBLE)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as decimal(10, 0)) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) / CAST(1 AS DECIMAL(10,0))):decimal(21,11)>
-- !query output
1.00000000000


-- !query
SELECT cast(1 as decimal(10, 0)) / cast(1 as string) FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) / CAST(1 AS STRING)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as decimal(10, 0)) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS DECIMAL(10,0)) / CAST(1 AS BINARY))\"",
    "left" : "\"DECIMAL(10,0)\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 61,
    "fragment" : "SELECT cast(1 as decimal(10, 0)) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast(1 as decimal(10, 0)) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS DECIMAL(10,0)) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"DECIMAL(10,0)\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 60,
    "fragment" : "SELECT cast(1 as decimal(10, 0)) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast(1 as decimal(10, 0)) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS DECIMAL(10,0)) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"DECIMAL(10,0)\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 84,
    "fragment" : "SELECT cast(1 as decimal(10, 0)) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast(1 as decimal(10, 0)) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS DECIMAL(10,0)) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"DECIMAL(10,0)\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 77,
    "fragment" : "SELECT cast(1 as decimal(10, 0)) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast(1 as string) / cast(1 as tinyint) FROM t
-- !query schema
struct<(CAST(1 AS STRING) / CAST(1 AS TINYINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as string) / cast(1 as smallint) FROM t
-- !query schema
struct<(CAST(1 AS STRING) / CAST(1 AS SMALLINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as string) / cast(1 as int) FROM t
-- !query schema
struct<(CAST(1 AS STRING) / CAST(1 AS INT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as string) / cast(1 as bigint) FROM t
-- !query schema
struct<(CAST(1 AS STRING) / CAST(1 AS BIGINT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as string) / cast(1 as float) FROM t
-- !query schema
struct<(CAST(1 AS STRING) / CAST(1 AS FLOAT)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as string) / cast(1 as double) FROM t
-- !query schema
struct<(CAST(1 AS STRING) / CAST(1 AS DOUBLE)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as string) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<(CAST(1 AS STRING) / CAST(1 AS DECIMAL(10,0))):double>
-- !query output
1.0


-- !query
SELECT cast(1 as string) / cast(1 as string) FROM t
-- !query schema
struct<(CAST(1 AS STRING) / CAST(1 AS STRING)):double>
-- !query output
1.0


-- !query
SELECT cast(1 as string) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS STRING) / CAST(1 AS BINARY))\"",
    "left" : "\"DOUBLE\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 53,
    "fragment" : "SELECT cast(1 as string) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast(1 as string) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS STRING) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"DOUBLE\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 52,
    "fragment" : "SELECT cast(1 as string) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast(1 as string) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS STRING) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"DOUBLE\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 76,
    "fragment" : "SELECT cast(1 as string) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast(1 as string) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS STRING) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"DOUBLE\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 69,
    "fragment" : "SELECT cast(1 as string) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast(1 as tinyint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(1 AS TINYINT))\"",
    "left" : "\"BINARY\"",
    "right" : "\"TINYINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 54,
    "fragment" : "SELECT cast('1' as binary) / cast(1 as tinyint) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast(1 as smallint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(1 AS SMALLINT))\"",
    "left" : "\"BINARY\"",
    "right" : "\"SMALLINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 55,
    "fragment" : "SELECT cast('1' as binary) / cast(1 as smallint) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast(1 as int) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(1 AS INT))\"",
    "left" : "\"BINARY\"",
    "right" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 50,
    "fragment" : "SELECT cast('1' as binary) / cast(1 as int) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast(1 as bigint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(1 AS BIGINT))\"",
    "left" : "\"BINARY\"",
    "right" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 53,
    "fragment" : "SELECT cast('1' as binary) / cast(1 as bigint) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast(1 as float) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(1 AS FLOAT))\"",
    "left" : "\"BINARY\"",
    "right" : "\"FLOAT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 52,
    "fragment" : "SELECT cast('1' as binary) / cast(1 as float) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast(1 as double) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(1 AS DOUBLE))\"",
    "left" : "\"BINARY\"",
    "right" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 53,
    "fragment" : "SELECT cast('1' as binary) / cast(1 as double) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(1 AS DECIMAL(10,0)))\"",
    "left" : "\"BINARY\"",
    "right" : "\"DECIMAL(10,0)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 61,
    "fragment" : "SELECT cast('1' as binary) / cast(1 as decimal(10, 0)) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast(1 as string) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(1 AS STRING))\"",
    "left" : "\"BINARY\"",
    "right" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 53,
    "fragment" : "SELECT cast('1' as binary) / cast(1 as string) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_WRONG_TYPE",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(1 AS BINARY))\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "actualDataType" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 55,
    "fragment" : "SELECT cast('1' as binary) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"BINARY\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 54,
    "fragment" : "SELECT cast('1' as binary) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"BINARY\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 78,
    "fragment" : "SELECT cast('1' as binary) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast('1' as binary) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BINARY) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"BINARY\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 71,
    "fragment" : "SELECT cast('1' as binary) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast(1 as tinyint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(1 AS TINYINT))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"TINYINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 53,
    "fragment" : "SELECT cast(1 as boolean) / cast(1 as tinyint) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast(1 as smallint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(1 AS SMALLINT))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"SMALLINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 54,
    "fragment" : "SELECT cast(1 as boolean) / cast(1 as smallint) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast(1 as int) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(1 AS INT))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 49,
    "fragment" : "SELECT cast(1 as boolean) / cast(1 as int) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast(1 as bigint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(1 AS BIGINT))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 52,
    "fragment" : "SELECT cast(1 as boolean) / cast(1 as bigint) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast(1 as float) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(1 AS FLOAT))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"FLOAT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 51,
    "fragment" : "SELECT cast(1 as boolean) / cast(1 as float) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast(1 as double) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(1 AS DOUBLE))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 52,
    "fragment" : "SELECT cast(1 as boolean) / cast(1 as double) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(1 AS DECIMAL(10,0)))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"DECIMAL(10,0)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 60,
    "fragment" : "SELECT cast(1 as boolean) / cast(1 as decimal(10, 0)) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast(1 as string) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(1 AS STRING))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 52,
    "fragment" : "SELECT cast(1 as boolean) / cast(1 as string) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(1 AS BINARY))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 54,
    "fragment" : "SELECT cast(1 as boolean) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_WRONG_TYPE",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(1 AS BOOLEAN))\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "actualDataType" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 53,
    "fragment" : "SELECT cast(1 as boolean) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 77,
    "fragment" : "SELECT cast(1 as boolean) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast(1 as boolean) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"BOOLEAN\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 70,
    "fragment" : "SELECT cast(1 as boolean) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as tinyint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(1 AS TINYINT))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"TINYINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 77,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as tinyint) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as smallint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(1 AS SMALLINT))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"SMALLINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 78,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as smallint) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as int) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(1 AS INT))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 73,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as int) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as bigint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(1 AS BIGINT))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 76,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as bigint) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as float) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(1 AS FLOAT))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"FLOAT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 75,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as float) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as double) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(1 AS DOUBLE))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 76,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as double) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(1 AS DECIMAL(10,0)))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"DECIMAL(10,0)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 84,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as decimal(10, 0)) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as string) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(1 AS STRING))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 76,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as string) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(1 AS BINARY))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 78,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 77,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_WRONG_TYPE",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "actualDataType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 101,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "left" : "\"TIMESTAMP\"",
    "right" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 94,
    "fragment" : "SELECT cast('2017-12-11 09:30:00.0' as timestamp) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as tinyint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(1 AS TINYINT))\"",
    "left" : "\"DATE\"",
    "right" : "\"TINYINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 70,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as tinyint) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as smallint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(1 AS SMALLINT))\"",
    "left" : "\"DATE\"",
    "right" : "\"SMALLINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 71,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as smallint) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as int) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(1 AS INT))\"",
    "left" : "\"DATE\"",
    "right" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 66,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as int) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as bigint) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(1 AS BIGINT))\"",
    "left" : "\"DATE\"",
    "right" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 69,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as bigint) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as float) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(1 AS FLOAT))\"",
    "left" : "\"DATE\"",
    "right" : "\"FLOAT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 68,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as float) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as double) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(1 AS DOUBLE))\"",
    "left" : "\"DATE\"",
    "right" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 69,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as double) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as decimal(10, 0)) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(1 AS DECIMAL(10,0)))\"",
    "left" : "\"DATE\"",
    "right" : "\"DECIMAL(10,0)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 77,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as decimal(10, 0)) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as string) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(1 AS STRING))\"",
    "left" : "\"DATE\"",
    "right" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 69,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as string) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast('1' as binary) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(1 AS BINARY))\"",
    "left" : "\"DATE\"",
    "right" : "\"BINARY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 71,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast('1' as binary) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as boolean) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(1 AS BOOLEAN))\"",
    "left" : "\"DATE\"",
    "right" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 70,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast(1 as boolean) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\"",
    "left" : "\"DATE\"",
    "right" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 94,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast('2017-12-11 09:30:00.0' as timestamp) FROM t"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date) / cast('2017-12-11 09:30:00' as date) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_WRONG_TYPE",
  "messageParameters" : {
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / CAST(2017-12-11 09:30:00 AS DATE))\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "actualDataType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 87,
    "fragment" : "SELECT cast('2017-12-11 09:30:00' as date) / cast('2017-12-11 09:30:00' as date) FROM t"
  } ]
}
