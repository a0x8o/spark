-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 37


-- !query
CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES
(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2), (null, 1), (3, null), (null, null)
AS testData(a, b)
-- !query schema
struct<>
-- !query output



-- !query
CREATE OR REPLACE TEMPORARY VIEW EMP AS SELECT * FROM VALUES
  (100, "emp 1", date "2005-01-01", 100.00D, 10),
  (100, "emp 1", date "2005-01-01", 100.00D, 10),
  (200, "emp 2", date "2003-01-01", 200.00D, 10),
  (300, "emp 3", date "2002-01-01", 300.00D, 20),
  (400, "emp 4", date "2005-01-01", 400.00D, 30),
  (500, "emp 5", date "2001-01-01", 400.00D, NULL),
  (600, "emp 6 - no dept", date "2001-01-01", 400.00D, 100),
  (700, "emp 7", date "2010-01-01", 400.00D, 100),
  (800, "emp 8", date "2016-01-01", 150.00D, 70)
AS EMP(id, emp_name, hiredate, salary, dept_id)
-- !query schema
struct<>
-- !query output



-- !query
CREATE OR REPLACE TEMPORARY VIEW DEPT AS SELECT * FROM VALUES
  (10, "dept 1", "CA"),
  (20, "dept 2", "NY"),
  (30, "dept 3", "TX"),
  (40, "dept 4 - unassigned", "OR"),
  (50, "dept 5 - unassigned", "NJ"),
  (70, "dept 7", "FL")
AS DEPT(dept_id, dept_name, state)
-- !query schema
struct<>
-- !query output



-- !query
SELECT a, COUNT(b) FILTER (WHERE a >= 2) FROM testData
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
grouping expressions sequence is empty, and 'testdata.`a`' is not an aggregate function. Wrap '(count(testdata.`b`) FILTER (WHERE (testdata.`a` >= 2)) AS `count(b) FILTER (WHERE (a >= 2))`)' in windowing function(s) or wrap 'testdata.`a`' in first() (or first_value) if you don't care which value you get.;


-- !query
SELECT COUNT(a) FILTER (WHERE a = 1), COUNT(b) FILTER (WHERE a > 1) FROM testData
-- !query schema
struct<count(a) FILTER (WHERE (a = 1)):bigint,count(b) FILTER (WHERE (a > 1)):bigint>
-- !query output
2	4


-- !query
SELECT COUNT(id) FILTER (WHERE hiredate = date "2001-01-01") FROM emp
-- !query schema
struct<count(id) FILTER (WHERE (hiredate = DATE '2001-01-01')):bigint>
-- !query output
2


-- !query
SELECT COUNT(id) FILTER (WHERE hiredate = to_date('2001-01-01 00:00:00')) FROM emp
-- !query schema
struct<count(id) FILTER (WHERE (hiredate = to_date(2001-01-01 00:00:00))):bigint>
-- !query output
2


-- !query
SELECT COUNT(id) FILTER (WHERE hiredate = to_timestamp("2001-01-01 00:00:00")) FROM emp
-- !query schema
struct<count(id) FILTER (WHERE (CAST(hiredate AS TIMESTAMP) = to_timestamp(2001-01-01 00:00:00))):bigint>
-- !query output
2


-- !query
SELECT COUNT(id) FILTER (WHERE date_format(hiredate, "yyyy-MM-dd") = "2001-01-01") FROM emp
-- !query schema
struct<count(id) FILTER (WHERE (date_format(CAST(hiredate AS TIMESTAMP), yyyy-MM-dd) = 2001-01-01)):bigint>
-- !query output
2


-- !query
SELECT a, COUNT(b) FILTER (WHERE a >= 2) FROM testData GROUP BY a
-- !query schema
struct<a:int,count(b) FILTER (WHERE (a >= 2)):bigint>
-- !query output
1	0
2	2
3	2
NULL	0


-- !query
SELECT a, COUNT(b) FILTER (WHERE a != 2) FROM testData GROUP BY b
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;


-- !query
SELECT COUNT(a) FILTER (WHERE a >= 0), COUNT(b) FILTER (WHERE a >= 3) FROM testData GROUP BY a
-- !query schema
struct<count(a) FILTER (WHERE (a >= 0)):bigint,count(b) FILTER (WHERE (a >= 3)):bigint>
-- !query output
0	0
2	0
2	0
3	2


-- !query
SELECT dept_id, SUM(salary) FILTER (WHERE hiredate > date "2003-01-01") FROM emp GROUP BY dept_id
-- !query schema
struct<dept_id:int,sum(salary) FILTER (WHERE (hiredate > DATE '2003-01-01')):double>
-- !query output
10	200.0
100	400.0
20	NULL
30	400.0
70	150.0
NULL	NULL


-- !query
SELECT dept_id, SUM(salary) FILTER (WHERE hiredate > to_date("2003-01-01")) FROM emp GROUP BY dept_id
-- !query schema
struct<dept_id:int,sum(salary) FILTER (WHERE (hiredate > to_date(2003-01-01))):double>
-- !query output
10	200.0
100	400.0
20	NULL
30	400.0
70	150.0
NULL	NULL


-- !query
SELECT dept_id, SUM(salary) FILTER (WHERE hiredate > to_timestamp("2003-01-01 00:00:00")) FROM emp GROUP BY dept_id
-- !query schema
struct<dept_id:int,sum(salary) FILTER (WHERE (CAST(hiredate AS TIMESTAMP) > to_timestamp(2003-01-01 00:00:00))):double>
-- !query output
10	200.0
100	400.0
20	NULL
30	400.0
70	150.0
NULL	NULL


-- !query
SELECT dept_id, SUM(salary) FILTER (WHERE date_format(hiredate, "yyyy-MM-dd") > "2003-01-01") FROM emp GROUP BY dept_id
-- !query schema
struct<dept_id:int,sum(salary) FILTER (WHERE (date_format(CAST(hiredate AS TIMESTAMP), yyyy-MM-dd) > 2003-01-01)):double>
-- !query output
10	200.0
100	400.0
20	NULL
30	400.0
70	150.0
NULL	NULL


-- !query
SELECT 'foo', COUNT(a) FILTER (WHERE b <= 2) FROM testData GROUP BY 1
-- !query schema
struct<foo:string,count(a) FILTER (WHERE (b <= 2)):bigint>
-- !query output
foo	6


-- !query
SELECT 'foo', SUM(salary) FILTER (WHERE hiredate >= date "2003-01-01") FROM emp GROUP BY 1
-- !query schema
struct<foo:string,sum(salary) FILTER (WHERE (hiredate >= DATE '2003-01-01')):double>
-- !query output
foo	1350.0


-- !query
SELECT 'foo', SUM(salary) FILTER (WHERE hiredate >= to_date("2003-01-01")) FROM emp GROUP BY 1
-- !query schema
struct<foo:string,sum(salary) FILTER (WHERE (hiredate >= to_date(2003-01-01))):double>
-- !query output
foo	1350.0


-- !query
SELECT 'foo', SUM(salary) FILTER (WHERE hiredate >= to_timestamp("2003-01-01")) FROM emp GROUP BY 1
-- !query schema
struct<foo:string,sum(salary) FILTER (WHERE (CAST(hiredate AS TIMESTAMP) >= to_timestamp(2003-01-01))):double>
-- !query output
foo	1350.0


-- !query
select dept_id, count(distinct emp_name), count(distinct hiredate), sum(salary), sum(salary) filter (where id > 200) from emp group by dept_id
-- !query schema
struct<dept_id:int,count(DISTINCT emp_name):bigint,count(DISTINCT hiredate):bigint,sum(salary):double,sum(salary) FILTER (WHERE (id > 200)):double>
-- !query output
10	2	2	400.0	NULL
100	2	2	800.0	800.0
20	1	1	300.0	300.0
30	1	1	400.0	400.0
70	1	1	150.0	150.0
NULL	1	1	400.0	400.0


-- !query
select dept_id, count(distinct emp_name), count(distinct hiredate), sum(salary), sum(salary) filter (where id + dept_id > 500) from emp group by dept_id
-- !query schema
struct<dept_id:int,count(DISTINCT emp_name):bigint,count(DISTINCT hiredate):bigint,sum(salary):double,sum(salary) FILTER (WHERE ((id + dept_id) > 500)):double>
-- !query output
10	2	2	400.0	NULL
100	2	2	800.0	800.0
20	1	1	300.0	NULL
30	1	1	400.0	NULL
70	1	1	150.0	150.0
NULL	1	1	400.0	NULL


-- !query
select dept_id, count(distinct emp_name), count(distinct hiredate), sum(salary) filter (where salary < 400.00D), sum(salary) filter (where id > 200) from emp group by dept_id
-- !query schema
struct<dept_id:int,count(DISTINCT emp_name):bigint,count(DISTINCT hiredate):bigint,sum(salary) FILTER (WHERE (salary < 400.0)):double,sum(salary) FILTER (WHERE (id > 200)):double>
-- !query output
10	2	2	400.0	NULL
100	2	2	NULL	800.0
20	1	1	300.0	300.0
30	1	1	NULL	400.0
70	1	1	150.0	150.0
NULL	1	1	NULL	400.0


-- !query
select dept_id, count(distinct emp_name), count(distinct hiredate), sum(salary) filter (where salary < 400.00D), sum(salary) filter (where id + dept_id > 500) from emp group by dept_id
-- !query schema
struct<dept_id:int,count(DISTINCT emp_name):bigint,count(DISTINCT hiredate):bigint,sum(salary) FILTER (WHERE (salary < 400.0)):double,sum(salary) FILTER (WHERE ((id + dept_id) > 500)):double>
-- !query output
10	2	2	400.0	NULL
100	2	2	NULL	800.0
20	1	1	300.0	NULL
30	1	1	NULL	NULL
70	1	1	150.0	150.0
NULL	1	1	NULL	NULL


-- !query
SELECT 'foo', APPROX_COUNT_DISTINCT(a) FILTER (WHERE b >= 0) FROM testData WHERE a = 0 GROUP BY 1
-- !query schema
struct<foo:string,approx_count_distinct(a) FILTER (WHERE (b >= 0)):bigint>
-- !query output



-- !query
SELECT 'foo', MAX(STRUCT(a)) FILTER (WHERE b >= 1) FROM testData WHERE a = 0 GROUP BY 1
-- !query schema
struct<foo:string,max(struct(a)) FILTER (WHERE (b >= 1)):struct<a:int>>
-- !query output



-- !query
SELECT a + b, COUNT(b) FILTER (WHERE b >= 2) FROM testData GROUP BY a + b
-- !query schema
struct<(a + b):int,count(b) FILTER (WHERE (b >= 2)):bigint>
-- !query output
2	0
3	1
4	1
5	1
NULL	0


-- !query
SELECT a + 2, COUNT(b) FILTER (WHERE b IN (1, 2)) FROM testData GROUP BY a + 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
expression 'testdata.`a`' is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don't care which value you get.;


-- !query
SELECT a + 1 + 1, COUNT(b) FILTER (WHERE b > 0) FROM testData GROUP BY a + 1
-- !query schema
struct<((a + 1) + 1):int,count(b) FILTER (WHERE (b > 0)):bigint>
-- !query output
3	2
4	2
5	2
NULL	1


-- !query
SELECT a AS k, COUNT(b) FILTER (WHERE b > 0) FROM testData GROUP BY k
-- !query schema
struct<k:int,count(b) FILTER (WHERE (b > 0)):bigint>
-- !query output
1	2
2	2
3	2
NULL	1


-- !query
SELECT emp.dept_id,
       avg(salary),
       avg(salary) FILTER (WHERE id > (SELECT 200))
FROM emp
GROUP BY dept_id
-- !query schema
struct<dept_id:int,avg(salary):double,avg(salary) FILTER (WHERE (id > scalarsubquery())):double>
-- !query output
10	133.33333333333334	NULL
100	400.0	400.0
20	300.0	300.0
30	400.0	400.0
70	150.0	150.0
NULL	400.0	400.0


-- !query
SELECT emp.dept_id,
       avg(salary),
       avg(salary) FILTER (WHERE emp.dept_id = (SELECT dept_id FROM dept LIMIT 1))
FROM emp
GROUP BY dept_id
-- !query schema
struct<dept_id:int,avg(salary):double,avg(salary) FILTER (WHERE (dept_id = scalarsubquery())):double>
-- !query output
10	133.33333333333334	133.33333333333334
100	400.0	NULL
20	300.0	NULL
30	400.0	NULL
70	150.0	NULL
NULL	400.0	NULL


-- !query
SELECT emp.dept_id,
       avg(salary),
       avg(salary) FILTER (WHERE EXISTS (SELECT state
               FROM dept
               WHERE dept.dept_id = emp.dept_id))
FROM emp
GROUP BY dept_id
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
IN/EXISTS predicate sub-queries can only be used in Filter/Join and a few commands: Aggregate [dept_id#x], [dept_id#x, avg(salary#x) AS avg(salary)#x, avg(salary#x) FILTER (WHERE exists#x [dept_id#x]) AS avg(salary) FILTER (WHERE exists(dept_id))#x]
:  +- Project [state#x]
:     +- Filter (dept_id#x = outer(dept_id#x))
:        +- SubqueryAlias dept
:           +- Project [dept_id#x, dept_name#x, state#x]
:              +- SubqueryAlias DEPT
:                 +- LocalRelation [dept_id#x, dept_name#x, state#x]
+- SubqueryAlias emp
   +- Project [id#x, emp_name#x, hiredate#x, salary#x, dept_id#x]
      +- SubqueryAlias EMP
         +- LocalRelation [id#x, emp_name#x, hiredate#x, salary#x, dept_id#x]
;


-- !query
SELECT emp.dept_id, 
       Sum(salary),
       Sum(salary) FILTER (WHERE NOT EXISTS (SELECT state 
                   FROM dept 
                   WHERE dept.dept_id = emp.dept_id))
FROM emp 
GROUP BY dept_id
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
IN/EXISTS predicate sub-queries can only be used in Filter/Join and a few commands: Aggregate [dept_id#x], [dept_id#x, sum(salary#x) AS sum(salary)#x, sum(salary#x) FILTER (WHERE NOT exists#x [dept_id#x]) AS sum(salary) FILTER (WHERE (NOT exists(dept_id)))#x]
:  +- Project [state#x]
:     +- Filter (dept_id#x = outer(dept_id#x))
:        +- SubqueryAlias dept
:           +- Project [dept_id#x, dept_name#x, state#x]
:              +- SubqueryAlias DEPT
:                 +- LocalRelation [dept_id#x, dept_name#x, state#x]
+- SubqueryAlias emp
   +- Project [id#x, emp_name#x, hiredate#x, salary#x, dept_id#x]
      +- SubqueryAlias EMP
         +- LocalRelation [id#x, emp_name#x, hiredate#x, salary#x, dept_id#x]
;


-- !query
SELECT emp.dept_id, 
       avg(salary),
       avg(salary) FILTER (WHERE emp.dept_id IN (SELECT DISTINCT dept_id
               FROM dept))
FROM emp 
GROUP BY dept_id
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
IN/EXISTS predicate sub-queries can only be used in Filter/Join and a few commands: Aggregate [dept_id#x], [dept_id#x, avg(salary#x) AS avg(salary)#x, avg(salary#x) FILTER (WHERE dept_id#x IN (list#x [])) AS avg(salary) FILTER (WHERE (dept_id IN (listquery())))#x]
:  +- Distinct
:     +- Project [dept_id#x]
:        +- SubqueryAlias dept
:           +- Project [dept_id#x, dept_name#x, state#x]
:              +- SubqueryAlias DEPT
:                 +- LocalRelation [dept_id#x, dept_name#x, state#x]
+- SubqueryAlias emp
   +- Project [id#x, emp_name#x, hiredate#x, salary#x, dept_id#x]
      +- SubqueryAlias EMP
         +- LocalRelation [id#x, emp_name#x, hiredate#x, salary#x, dept_id#x]
;


-- !query
SELECT emp.dept_id, 
       Sum(salary),
       Sum(salary) FILTER (WHERE emp.dept_id NOT IN (SELECT DISTINCT dept_id
               FROM dept))
FROM emp 
GROUP BY dept_id
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
IN/EXISTS predicate sub-queries can only be used in Filter/Join and a few commands: Aggregate [dept_id#x], [dept_id#x, sum(salary#x) AS sum(salary)#x, sum(salary#x) FILTER (WHERE NOT dept_id#x IN (list#x [])) AS sum(salary) FILTER (WHERE (NOT (dept_id IN (listquery()))))#x]
:  +- Distinct
:     +- Project [dept_id#x]
:        +- SubqueryAlias dept
:           +- Project [dept_id#x, dept_name#x, state#x]
:              +- SubqueryAlias DEPT
:                 +- LocalRelation [dept_id#x, dept_name#x, state#x]
+- SubqueryAlias emp
   +- Project [id#x, emp_name#x, hiredate#x, salary#x, dept_id#x]
      +- SubqueryAlias EMP
         +- LocalRelation [id#x, emp_name#x, hiredate#x, salary#x, dept_id#x]
;


-- !query
SELECT t1.b FROM (SELECT COUNT(b) FILTER (WHERE a >= 2) AS b FROM testData) t1
-- !query schema
struct<b:bigint>
-- !query output
4
