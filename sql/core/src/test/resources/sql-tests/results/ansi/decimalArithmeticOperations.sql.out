-- Automatically generated by SQLQueryTestSuite
-- !query
create table decimals_test(id int, a decimal(38,18), b decimal(38,18)) using parquet
-- !query schema
struct<>
-- !query output



-- !query
insert into decimals_test values(1, 100.0, 999.0), (2, 12345.123, 12345.123),
  (3, 0.1234567891011, 1234.1), (4, 123456789123456789.0, 1.123456789123456789)
-- !query schema
struct<>
-- !query output



-- !query
select id, a*10, b/10 from decimals_test order by id
-- !query schema
struct<id:int,(a * 10):decimal(38,15),(b / 10):decimal(38,18)>
-- !query output
1	1000.000000000000000	99.900000000000000000
2	123451.230000000000000	1234.512300000000000000
3	1.234567891011000	123.410000000000000000
4	1234567891234567890.000000000000000	0.112345678912345679


-- !query
select 10.3 * 3.0
-- !query schema
struct<(10.3 * 3.0):decimal(6,2)>
-- !query output
30.90


-- !query
select 10.3000 * 3.0
-- !query schema
struct<(10.3000 * 3.0):decimal(9,5)>
-- !query output
30.90000


-- !query
select 10.30000 * 30.0
-- !query schema
struct<(10.30000 * 30.0):decimal(11,6)>
-- !query output
309.000000


-- !query
select 10.300000000000000000 * 3.000000000000000000
-- !query schema
struct<(10.300000000000000000 * 3.000000000000000000):decimal(38,34)>
-- !query output
30.9000000000000000000000000000000000


-- !query
select 10.300000000000000000 * 3.0000000000000000000
-- !query schema
struct<(10.300000000000000000 * 3.0000000000000000000):decimal(38,34)>
-- !query output
30.9000000000000000000000000000000000


-- !query
select (5e36BD + 0.1) + 5e36BD
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CANNOT_CHANGE_DECIMAL_PRECISION] Decimal(expanded, 10000000000000000000000000000000000000.1, 39, 1) cannot be represented as Decimal(38, 1). If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
select (5e36BD + 0.1) + 5e36BD
       ^^^^^^^^^^^^^^^^^^^^^^^


-- !query
select (-4e36BD - 0.1) - 7e36BD
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CANNOT_CHANGE_DECIMAL_PRECISION] Decimal(expanded, -11000000000000000000000000000000000000.1, 39, 1) cannot be represented as Decimal(38, 1). If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
select (-4e36BD - 0.1) - 7e36BD
       ^^^^^^^^^^^^^^^^^^^^^^^^


-- !query
select 12345678901234567890.0 * 12345678901234567890.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CANNOT_CHANGE_DECIMAL_PRECISION] Decimal(expanded, 152415787532388367501905199875019052100, 39, 0) cannot be represented as Decimal(38, 2). If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
select 12345678901234567890.0 * 12345678901234567890.0
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


-- !query
select 1e35BD / 0.1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CANNOT_CHANGE_DECIMAL_PRECISION] Decimal(expanded, 1000000000000000000000000000000000000.00000000000000000000000000000000000000, 75, 38) cannot be represented as Decimal(38, 6). If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
select 1e35BD / 0.1
       ^^^^^^^^^^^^


-- !query
select 123456789123456789.1234567890 * 1.123456789123456789
-- !query schema
struct<(123456789123456789.1234567890 * 1.123456789123456789):decimal(38,18)>
-- !query output
138698367904130467.654320988515622621


-- !query
select 123456789123456789.1234567890 * 1.123456789123456789
-- !query schema
struct<(123456789123456789.1234567890 * 1.123456789123456789):decimal(38,18)>
-- !query output
138698367904130467.654320988515622621


-- !query
select 12345678912345.123456789123 / 0.000000012345678
-- !query schema
struct<(12345678912345.123456789123 / 1.2345678E-8):decimal(38,9)>
-- !query output
1000000073899961059796.725866332


-- !query
select 1.0123456789012345678901234567890123456e36BD / 0.1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CANNOT_CHANGE_DECIMAL_PRECISION] Decimal(expanded, 10123456789012345678901234567890123456.00000000000000000000000000000000000000, 76, 38) cannot be represented as Decimal(38, 6). If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
select 1.0123456789012345678901234567890123456e36BD / 0.1
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


-- !query
select 1.0123456789012345678901234567890123456e35BD / 1.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CANNOT_CHANGE_DECIMAL_PRECISION] Decimal(expanded, 101234567890123456789012345678901234.56000000000000000000000000000000000000, 74, 38) cannot be represented as Decimal(38, 6). If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
select 1.0123456789012345678901234567890123456e35BD / 1.0
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


-- !query
select 1.0123456789012345678901234567890123456e34BD / 1.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CANNOT_CHANGE_DECIMAL_PRECISION] Decimal(expanded, 10123456789012345678901234567890123.45600000000000000000000000000000000000, 73, 38) cannot be represented as Decimal(38, 6). If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
select 1.0123456789012345678901234567890123456e34BD / 1.0
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


-- !query
select 1.0123456789012345678901234567890123456e33BD / 1.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CANNOT_CHANGE_DECIMAL_PRECISION] Decimal(expanded, 1012345678901234567890123456789012.34560000000000000000000000000000000000, 72, 38) cannot be represented as Decimal(38, 6). If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
select 1.0123456789012345678901234567890123456e33BD / 1.0
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


-- !query
select 1.0123456789012345678901234567890123456e32BD / 1.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CANNOT_CHANGE_DECIMAL_PRECISION] Decimal(expanded, 101234567890123456789012345678901.23456000000000000000000000000000000000, 71, 38) cannot be represented as Decimal(38, 6). If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
select 1.0123456789012345678901234567890123456e32BD / 1.0
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


-- !query
select 1.0123456789012345678901234567890123456e31BD / 1.0
-- !query schema
struct<(10123456789012345678901234567890.123456 / 1.0):decimal(38,6)>
-- !query output
10123456789012345678901234567890.123456


-- !query
select 1.0123456789012345678901234567890123456e31BD / 0.1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CANNOT_CHANGE_DECIMAL_PRECISION] Decimal(expanded, 101234567890123456789012345678901.23456000000000000000000000000000000000, 71, 38) cannot be represented as Decimal(38, 6). If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
select 1.0123456789012345678901234567890123456e31BD / 0.1
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


-- !query
select 1.0123456789012345678901234567890123456e31BD / 10.0
-- !query schema
struct<(10123456789012345678901234567890.123456 / 10.0):decimal(38,6)>
-- !query output
1012345678901234567890123456789.012346


-- !query
drop table decimals_test
-- !query schema
struct<>
-- !query output

